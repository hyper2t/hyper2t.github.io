[{"categories":["C++"],"content":"这篇文章总结了 C++ 中面向对象编程的知识体系：类的继承，包括其中的底层实现等等。","date":"2020-08-19","objectID":"/inheritance/","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 2: 类的继承","uri":"/inheritance/"},{"categories":["C++"],"content":"这篇文章总结了 C++ 中面向对象编程的知识体系：类的继承，包括其中的底层实现等等。 ","date":"2020-08-19","objectID":"/inheritance/:0:0","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 2: 类的继承","uri":"/inheritance/"},{"categories":["C++"],"content":"1 类的继承 ","date":"2020-08-19","objectID":"/inheritance/:1:0","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 2: 类的继承","uri":"/inheritance/"},{"categories":["C++"],"content":"1.1 继承的定义 ","date":"2020-08-19","objectID":"/inheritance/:1:1","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 2: 类的继承","uri":"/inheritance/"},{"categories":["C++"],"content":"1.2 虚继承 基类： class Parent { // ... }; 子类： class Child : virtual public Parent { // ... }; 证明这个 Parent 是 Child 的虚基类。 虚基类是指：class SubClass : virtual public BaseClass 中以 virtual 声明的基类，由于 C++ 支持多重继承，所以对于一个派生类中有几个直接父类，而几个直接父类中有几个可能分别继承自某一个基类（就是父类的父类），这样在构造最终派生类时，会出现最终派生类中含有多个同一个基类的情况，就会产生二义性的问题（不知道该调用哪个基类的成员变量和函数），为解决此问题，需要使用虚基类，即只对此基类生成一块内存区域，这样最终派生类中就只会含有一个基类了。 典型的需要用虚基类的情况如下(菱形继承)： A / \\ B C \\ / D 其中 D 继承自 B C，B C 分别继承自 A，所以 A 要分别被 B C 虚拟继承： #include \u003ciostream\u003e using namespace std; class A { public: void printA() { cout \u003c\u003c \"this is A\\n\"; } }; class B : virtual public A {}; class C : virtual public A {}; class D : public B, public C {}; int main(int argc, char const* argv[]) { D* d = new D; d-\u003eprintA(); return 0; } 如果把 virtual 虚继承去掉，会报错为： error: request for member ‘printA’ is ambiguous ","date":"2020-08-19","objectID":"/inheritance/:1:2","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 2: 类的继承","uri":"/inheritance/"},{"categories":["C++"],"content":"这篇文章总结了 C++ 中泛型编程的知识体系和实际应用中用到的框架，包括其中的底层实现等等。","date":"2020-08-15","objectID":"/generic-template/","tags":["C++","STL","模板","特化","偏特化","模板萃取"],"title":"C++ 泛型编程知识体系 part 1: 什么是模板","uri":"/generic-template/"},{"categories":["C++"],"content":"这篇文章初步介绍了 C++ 中泛型编程的知识体系，主要讲解了什么是模板。 ","date":"2020-08-15","objectID":"/generic-template/:0:0","tags":["C++","STL","模板","特化","偏特化","模板萃取"],"title":"C++ 泛型编程知识体系 part 1: 什么是模板","uri":"/generic-template/"},{"categories":["算法"],"content":"这篇文章总结了我刷Leetcode 时候用到的算法模板，包括回溯算法，二分法用到的双指针，动态规划等等。","date":"2020-08-13","objectID":"/algorithms/","tags":["动态规划","二分法","Algorithms"],"title":"刷 Leetcode 的算法总结","uri":"/algorithms/"},{"categories":["算法"],"content":"这篇文章总结了我刷 Leetcode 时候用到的算法模板，包括回溯算法，二分法用到的双指针，动态规划等等。 ","date":"2020-08-13","objectID":"/algorithms/:0:0","tags":["动态规划","二分法","Algorithms"],"title":"刷 Leetcode 的算法总结","uri":"/algorithms/"},{"categories":["算法"],"content":"1. 回溯算法 ","date":"2020-08-13","objectID":"/algorithms/:1:0","tags":["动态规划","二分法","Algorithms"],"title":"刷 Leetcode 的算法总结","uri":"/algorithms/"},{"categories":["算法"],"content":"1.1 解题过程 关于回溯算法，一般是通过在集合中递归查找子集，集合的大小构成树的宽度，递归的深度构成树的深度。 以下是回溯\"三部曲\"： 确定回溯函数的返回值和参数 确定回溯函数的终止条件 确定回溯搜索的遍历过程 ","date":"2020-08-13","objectID":"/algorithms/:1:1","tags":["动态规划","二分法","Algorithms"],"title":"刷 Leetcode 的算法总结","uri":"/algorithms/"},{"categories":["算法"],"content":"1.2 回溯模板 void backtracking(参数){ if (终止条件){ 存放结果; return; } for (选择：本层集合中的元素，即树中节点孩子的数量就是集合的大小){ 处理节点; backtracking(路径,选择列表); 回溯, 撤销处理结果; } } ","date":"2020-08-13","objectID":"/algorithms/:1:2","tags":["动态规划","二分法","Algorithms"],"title":"刷 Leetcode 的算法总结","uri":"/algorithms/"},{"categories":["算法"],"content":"1.3 Leetcode 实战 全排列 (Leetcode 46) 给定一个不含重复数字的数组nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。 示例 1： 输入：nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] 示例 2： 输入：nums = [0,1] 输出：[[0,1],[1,0]] 示例 3： 输入：nums = [1] 输出：[[1]] 提示： 1 $\\leq$ nums.length $\\leq$ 6 -10 $\\leq$ nums[i] $\\leq$ 10 nums 中的所有整数互不相同 解法如下： func permute(nums []int) [][]int { var res [][]int if len(nums) == 0 { return res } var tmp []int var visited = make([]bool, len(nums)) backtracking(nums, \u0026res, tmp, visited) return res } func backtracking(arr []int, res *[][]int, tmp []int, visited []bool) { // 成功找到一组 if len(tmp) == len(arr) { var c = make([]int, len(tmp)) copy(c, tmp) *res = append(*res, c) return } // 回溯 for i := 0; i \u003c len(arr); i++ { if !visited[i] { visited[i] = true tmp = append(tmp, arr[i]) backtracking(arr, res, tmp, visited) tmp = tmp[:len(tmp)-1] visited[i] = false } } } ","date":"2020-08-13","objectID":"/algorithms/:1:3","tags":["动态规划","二分法","Algorithms"],"title":"刷 Leetcode 的算法总结","uri":"/algorithms/"},{"categories":["C++"],"content":"这篇文章总结了 C++ 中面向对象编程的知识体系：构造函数和析构函数，包括其中的底层实现等等。","date":"2020-08-11","objectID":"/constructordestructor/","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["C++"],"content":"这篇文章总结了 C++ 中面向对象编程的知识体系：构造函数和析构函数，包括其中的底层实现等等。 ","date":"2020-08-11","objectID":"/constructordestructor/:0:0","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["C++"],"content":"1 面向对象特性 ","date":"2020-08-11","objectID":"/constructordestructor/:1:0","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["C++"],"content":"1. 类与对象 问题\r什么是类与对象？\r对象是现实中的对象在程序中的模拟 类是同一类对象的抽象，对象是类的某一特定实体 类是一种用户自定义的类型，包含函数与数据的特殊结构体 示例\r举一个简单的例子， class Orange{ public: int GetOrangeDegree(); // orange 的成员方法 int GetSourDegree(); int GetSweetDegree(); int GetWaterRatio(); private: int m_waterRatio; int m_orangeDegree; int m_sourDegree; int m_sweetDegree; } 这里所举的例子，Orange是类，但橙子有分不同个体，它们都有对应的酸度、甜度、水分和生长高度，所以不同的橙子个体代表着这一类橙子的不同对象。 类成员的访问控制 访问权限分为公有类型public，保护类型protected，私有类型private 成员默认访问权限为private 友元函数或者友元类可访问类的保护成员或私有成员 来看一个例子： 示例\rclass Teacher; class Student{ public: void SetId(uint32_t id){m_id = id;} uint32_t GetId(); friend Teacher; friend void PrintStudentId(Student); private: uint32_t m_id = 0; uint32_t m_age = 18; } class Teacher{ public: void PrintStudentId(Student stud) { std::cout \u003c\u003c stud.m_id \u003c\u003c std:endl; } } void PrintStudentId(Student stud) { std::cout \u003c\u003c stud.m_id \u003c\u003c std:endl; } 我们定义了 class Teacher, Teacher是Student的友元类，PrintStudentId是Student的友元函数，该函数可用于访问Student类的保护成员或者私有成员。 例如：就像上面所写的，Teacher类里面定义的PrintStudentId函数可以访问Student类的私有成员stud.m_id。 警告\r友元函数是单向的： 打个比方，Student把Teacher当成朋友，而Teacher不把Student当朋友。就如上面的例子，Teacher是Student的友元，但是Student不是Teacher的友元，所以Teacher类的成员函数在没有friend的关键字作用下，不能访问Teacher类的保护成员或者私有成员。 友元函数不是类的成员。 ","date":"2020-08-11","objectID":"/constructordestructor/:1:1","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["C++"],"content":"2. 类的构造与析构 构造函数 构造函数是用于构造函数的特殊函数，在对象被创建时被调用以初始化对象 未定义构造函数时，编译器自动生成不带参数的默认版本 执行构造函数时先执行其初始化列表，再执行函数体 构造函数和其他函数一样，允许被重载和被委托 构造函数的名称与类的名称是完全相同的，并且不会返回任何类型，也不会返回void。构造函数可用于为某些成员变量设置初始值。 构造函数主要有以下三个方面的作用： 给创建的对象建立一个标识符； 为对象数据成员开辟内存空间； 完成对象数据成员的初始化。 class Student{ public: Student(); Student(uint32_t id); Student(uint32_t id, uint32_t age); void SetId(uint32_t id){m_id = id;} uint32_t GetId(){return m_id;} private: uint32_t m_id = 0; uint32_t m_age; } 关于以上的Student类，我们声明了三个Student的构造函数。第一个构造函数Student()不带参数。三个构造函数的具体定义如下： Student::Student(uint32_t id, uint32_t age):m_id(id), m_age(age) { // do initialization } Student::Student():Student(0,18) { // do initialization } Student::Student(uint32_t id):Student(id,18) { // do initialization } 按照上面的写法，我们可以使用初始化列表进行初始化字段。假设有一个类C，具有多个字段X、Y、Z等需要进行初始化，同理地，您可以使用上面的语法，只需要在不同的字段使用逗号进行分隔，如下所示： C::C( double a, double b, double c): X(a), Y(b), Z(c) { .... } 问题\r既然构造函数允许被重载，构造函数是如何做到被重载呢？\r需要注意的是, 在进行构造函数的重载时要注意重载和参数默认的关系要处理好, 避免产生代码的二义性导致编译出错, 例如以下具有二义性的重载: 示例\rPoint(int x = 0, int y = 0) //默认参数的构造函数 { xPos = x; yPos = y; } Point() //重载一个无参构造函数 { xPos = 0; yPos = 0; } 在上面的重载中, 当尝试用Point类重载一个无参数传入的对象M时, Point M; 这时编译器就报一条error: call of overloaded 'Point()' is ambiguous的错误信息来告诉我们说 Point 函数具有二义性。 这是因为Point(int x = 0, int y = 0)全部使用了默认参数, 即使我们不传入参数也不会出现错误, 但是在重载时又重载了一个不需要传入参数了构造函数Point(), 这样就造成了当创建对象都不传入参数时编译器就不知道到底该使用哪个构造函数了, 就造成了二义性。 析构函数 与构造函数相反, 析构函数是在对象被撤销时被自动调用, 用于对成员撤销时的一些清理工作, 例如在前面提到的手动释放使用new或malloc进行申请的内存空间。析构函数具有以下特点: 析构函数函数名与类名相同, 紧贴在名称前面用波浪号 ~ 与构造函数进行区分, 例如: ~Point(); 构造函数没有返回类型, 也不能指定参数, 因此析构函数只能有一个, 不能被重载; 当对象被撤销时析构函数被自动调用, 与构造函数不同的是, 析构函数可以被显式的调用, 以释放对象中动态申请的内存。 某种意义上理解析构函数是回收间接资源的函数。 图1：析构函数回收间接资源\r#include \u003ciostream\u003e #include \u003ccstring\u003e using namespace std; class Book { public: Book( const char *name ) //构造函数 { bookName = new char[strlen(name)+1]; strcpy(bookName, name); } ~Book() //析构函数 { cout\u003c\u003c\"析构函数被调用...\\n\"; delete []bookName; //释放通过new申请的空间 } void showName() { cout\u003c\u003c\"Book name: \"\u003c\u003c bookName \u003c\u003cendl; } private: char *bookName; }; int main() { Book CPP(\"C++ Primer\"); CPP.showName(); return 0; } 代码中创建了一个Book类, 类的数据成员只有一个字符指针型的bookName, 在创建对象时系统会为该指针变量分配它所需内存, 但是此时该指针并没有被初始化所以不会再为其分配其他多余的内存单元。在构造函数中, 我们使用new申请了一块strlen(name)+1大小的空间, 也就是比传入进来的字符串长度多1的空间, 目的是让字符指针bookName指向它, 这样才能正常保存传入的字符串。 在main函数中使用Book类创建了一个对象CPP, 初始化bookName属性为\"C++ Primer\"。从运行结果可以看到, 析构函数被调用了, 这时使用new所申请的空间就会被正常释放。 自然状态下对象何时将被销毁取决于对象的生存周期, 例如全局对象是在程序运行结束时被销毁, 自动对象是在离开其作用域时被销毁。 如果需要显式调用析构函数来释放对象中动态申请的空间只需要使用 对象名.析构函数名(); 即可, 例如上例中要显式调用析构函数来释放bookName所指向的空间只要: CPP.~Book(); ","date":"2020-08-11","objectID":"/constructordestructor/:1:2","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["C++"],"content":"4. 类的继承 ","date":"2020-08-11","objectID":"/constructordestructor/:1:3","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["C++"],"content":"5. 类的多态 ","date":"2020-08-11","objectID":"/constructordestructor/:1:4","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["C++"],"content":"6. RTTI 与抽象类","date":"2020-08-11","objectID":"/constructordestructor/:1:5","tags":["C++","继承","多态","类"],"title":"C++ 面向对象编程知识体系 part 1: 构造函数与析构函数","uri":"/constructordestructor/"},{"categories":["Golang"],"content":"这篇文章总结了 Golang 的 sync 包，包括`sync.Map`、`sync.Once`、`sync.Pool`、其中 sync.Mutex 的底层实现等等。","date":"2020-08-09","objectID":"/semaphore/","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"这篇文章总结了 Golang 的sync包，包括sync.Map、sync.Once、sync.Pool、其中sync.Mutex的底层通过semaphore机制实现等等。 Go语言里对同步的支持主要有五类应用场景： 资源独占：当多个线程依赖同一份资源（比如数据），需要同时读/写同一个内存地址时，runtime需要保证只有一个修改这份数据，并且保证该修改对其他线程可见。锁和变量的原子操作为此而设计 生产者-消费者：在生产者-消费者模型中，消费者依赖生产者产出数据。 channel（管道）为此而设计 懒加载：一个资源，当且仅当第一次执行一个操作时，该操作执行过程中其他的同类操作都会被阻塞，直到该操作完成。sync.Once为此而设计 fork-join：一个任务首先创建出$N$个子任务，$N$个子任务全部执行完成以后，主任务搜集结果，执行后续操作。sync.WaitGroup为此而设计 条件变量：条件变量是一个同步原语，可以同时阻塞多个线程，直到另一个线程 1) 修改了条件; 2)通知一个（或所有）等待的线程。sync.Cond为此而设计 注意\r注意：这里当我说\"线程\"时，了解Go的同学可以自动映射到 “goroutine”(协程)。\r","date":"2020-08-09","objectID":"/semaphore/:0:0","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"1 sync.Map ","date":"2020-08-09","objectID":"/semaphore/:1:0","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"1. sync.Map 用法 sync.Map是一个线程安全的map结构，一般用于多读少写的并发操作，下图是sync.Map的数据结构: 图1：sync.Map的数据结构\r代码结构是： type Map struct { mu Mutex read atomic.Value // readOnly dirty map[interface{}]*entry misses int } mu是Map的互斥锁用于对并发操作进行加锁保护 read是用于存储只读内容的，可以提供高并发的读操作 dirty是一个原始的map结构体，对dirty的操作需要加锁，dirty包涵了全量的数据，在读数据的时候会先读取read，read读取不到再读dirty misses 是read读取失败的次数，当多次读取失败后 misses 累计特定值，dirty就会升级成read sync.Map这里采用的策略类似数据库常用的”读写分离”，技术都是相通的。具体例子如下： 示例\rfunc main() { var value sync.Map // 写入 value.Store(\"your name\", \"shi\") value.Store(\"her name\", \"kanon\") // 读取 name, ok := value.Load(\"your name\") if !ok { println(\"can't find name\") } fmt.Println(name) // 遍历 value.Range(func(ki, vi interface{}) bool { k, v := ki.(string), vi.(string) fmt.Println(k, v) return true }) // 删除 value.Delete(\"your name\") // 读取，如果不存在则写入 activename, loaded := value.LoadOrStore(\"his name\", \"baba\") fmt.Println(activename.(string), loaded) } ","date":"2020-08-09","objectID":"/semaphore/:1:1","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"2. 原理结构 Load func (m *Map) Load(key interface{}) (value interface{}, ok bool) { // 首先从只读字段读取内容 read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 如果没读到，并且dirty有read没有数据则从dirty中读取 if !ok \u0026\u0026 read.amended { m.mu.Lock() // 在从dirty读取前需要加锁后再做一次验证，防止期间read突然有数据，也就是double check read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026\u0026 read.amended { e, ok = m.dirty[key] // 将此次记录记录添加到miss中，可以看到这里没对dirty的取值做判断，也就是说不管是否 // 取到miss都会添加一次 m.missLocked() } m.mu.Unlock() } if !ok { return nil, false } return e.load() } Load方法讲解：首先从只读字段read中读取键值的内容，如果没读到，并且amended为true(dirty有read没有数据)则尝试从dirty中读取，不过这里要做 double check， 然后将此次缓存穿透记录一次到miss字段。 Store func (m *Map) Store(key, value interface{}) { // 存储之前先从只读字段读取要存储的值，如果存在，则用CAS的方式将新的值存储进去 read, _ := m.read.Load().(readOnly) // tryStore 会检查dirty的keys值是否已经删除， // 如果没有删除标记，则直接采用CAS方式存储entry if e, ok := read.m[key]; ok \u0026\u0026 e.tryStore(\u0026value) { return } m.mu.Lock() // double check read, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok { // double check 如果read存在，调用 unexpungeLocked 将 expunged 设置为 nil， // 然后更新dirty，expunged 表示dirty中记录的删除标识（read没同步），由于有新的值存储需要 // 将删除标识更新。 if e.unexpungeLocked() { m.dirty[key] = e } e.storeLocked(\u0026value) } else if e, ok := m.dirty[key]; ok { // 如果read中没有对应的键，从dirty中有则直接更新dirty中的键 e.storeLocked(\u0026value) } else { // dirty 和 read 都不存在这个键的情况 if !read.amended { // amended为true标识dirty包含read没有的key，由于dirty是最全的数据，amend为false只有两种 // 情况，一种就是 dirty 的键值等于 read 的键值，一种是dirty为空的时候，所以这里只有可能是 // 第二种，也就是dirty为空，因此再store 之前先判断一下 dirty map 是否为空，如果为空，就把 read map 浅拷贝一次。 m.dirtyLocked() m.read.Store(readOnly{m: read.m, amended: true}) } // 如果dirty数据和read的key不同步数据，直接将值写入dirty m.dirty[key] = newEntry(value) } m.mu.Unlock() } Store方法讲解：存储之前先从只读字段read中读取要存储的值，在read中存在键值对的时候，则用 CAS 的方式将新的值存储进去，如果不存在则加锁做个 double check，将新数据写入dirty中。如果dirty和read中都没数据，dirty和read的键值不同步，则将数据直接写入dirty， 如果dirty键值数据和read一样，同时dirty为nil，将read浅拷贝一份到dirty，为后面赋值可以同时写入dirty和read。 Delete func (m *Map) Delete(key interface{}) { m.LoadAndDelete(key) } func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) { read, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok \u0026\u0026 read.amended { m.mu.Lock() read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026\u0026 read.amended { e, ok = m.dirty[key] m.missLocked() } m.mu.Unlock() } if ok { return e.delete() } return nil, false } func (e *entry) delete() (value interface{}, ok bool) { for { p := atomic.LoadPointer(\u0026e.p) if p == nil || p == expunged { return nil, false } if atomic.CompareAndSwapPointer(\u0026e.p, p, nil) { return *(*interface{})(p), true } } } Delete方法讲解:sync.Map的 Delete 方法本质是用的读取和删除，也就是先读取到数据再对数据进行删除，读的方法和 Load 的方法是一样的。 Range func (m *Map) Range(f func(key, value interface{}) bool) { // 如果amend为ture，说明dirty包含了read所有的key，将dirty提升为read， // 并将dirty设置为nil，之后用Store存储新的值的时候再拷贝回来 // 最后对read进行遍历即可 read, _ := m.read.Load().(readOnly) if read.amended { m.mu.Lock() read, _ = m.read.Load().(readOnly) if read.amended { read = readOnly{m: m.dirty} m.read.Store(read) m.dirty = nil m.misses = 0 } m.mu.Unlock() } for k, e := range read.m { v, ok := e.load() if !ok { continue } if !f(k, v) { break } } } Range原理讲解：Range 本质是通过遍历只读字段read得到，为了让只读字段包含所有数据，当dirty和read不相等的时候，将dirty升级为read， 最后再对read进行遍历即可。 ","date":"2020-08-09","objectID":"/semaphore/:1:2","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"2 sync.Pool ","date":"2020-08-09","objectID":"/semaphore/:2:0","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"1. sync.Pool 用法 sync.Pool是一个用来缓存大量重复对象，减少大量对象创建给GC压力，是sync异步包中很重要的一种数据结构，看其基本数据结构： type Pool struct { // noCopy 表示不支持值拷贝，如果出现值拷贝用 go vet 编译检查的时候会报错 noCopy noCopy // [P]poolLocal，表示每个local的P池 local unsafe.Pointer // local的长度 localSize uintptr // 也是[P]poolLocal，表示上一个生命周期的local victim unsafe.Pointer // victim的长度 victimSize uintptr // 用于创建新对象方法，get获取不到就会调用创建一个新对象，一般由用户传入 New func() interface{} } 图2：sync.Pool的数据结构\rsync.Pool用法有三种方法，如下： 示例\r//初始化pool对象 var pool sync.Pool type peter struct { num int } // 创建新对象创建方法 func initPool() { pool = sync.Pool{ New: func() interface{} { return \u0026peter{num: rand.Int()} }, } } func main() { initPool() // 从pool对象池中取对象 p1 := pool.Get().(*peter) fmt.Println(\"p1\", p1.num) // 将对象放入pool对象池 pool.Put(p1) p2 := pool.Get().(*peter) fmt.Println(\"p2\", p2.num) } 首先，需要初始化Pool，唯一需要的就是设置好New函数。当调用Get方法时，如果池子里缓存了对象，就直接返回缓存的对象。如果没有存货，则调用New函数创建一个新的对象。 另外，我们发现Get方法取出来的对象和上次Put进去的对象实际上是同一个，Pool没有做任何“清空”的处理。但我们不应当对此有任何假设，因为在实际的并发使用场景中，无法保证这种顺序，最好的做法是在Put前，将对象清空。 ","date":"2020-08-09","objectID":"/semaphore/:2:1","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"2. 单元测试 为了测试Get/Put的功能。我们来看下TestPoolNew： func TestPoolNew(t *testing.T) { // disable GC so we can control when it happens. defer debug.SetGCPercent(debug.SetGCPercent(-1)) i := 0 p := Pool{ New: func() interface{} { i++ return i }, } if v := p.Get(); v != 1 { t.Fatalf(\"got %v; want 1\", v) } if v := p.Get(); v != 2 { t.Fatalf(\"got %v; want 2\", v) } // Make sure that the goroutine doesn't migrate to another P // between Put and Get calls. Runtime_procPin() p.Put(42) if v := p.Get(); v != 42 { t.Fatalf(\"got %v; want 42\", v) } Runtime_procUnpin() if v := p.Get(); v != 3 { t.Fatalf(\"got %v; want 3\", v) } } 问题\r首先设置了GC=-1，作用就是停止GC。函数都跑完了，那为啥要用defer？\r注意到，debug.SetGCPercent这个函数被调用了两次，而且这个函数返回的是上一次GC的值。因此，defer在这里的用途是还原到调用此函数之前的GC设置，也就是恢复现场。 调置了Pool的New函数：直接返回一个int，变且每次调用New，都会自增 1。然后，连续调用了两次Get函数，因为这个时候Pool里没有缓存的对象，因此每次都会调用New创建一个，所以第一次返回 1，第二次返回 2。 调用Runtime_procPin()防止 goroutine 被强占，目的是保护接下来的一次Put和Get操作，使得它们操作的对象都是同一个 P 的“池子”。并且，这次调用Get的时候并没有调用New，因为之前有一次Put的操作。 再次调用Get操作，因为没有“存货”，因此还是会再次调用New创建一个对象。 其他TestPool函数: TestPoolGC和TestPoolRelease则主要测试GC对Pool里对象的影响。这里用了一个函数，用于计数有多少对象会被GC回收： runtime.SetFinalizer(v, func(vv *string) { atomic.AddUint32(\u0026fin, 1) }) TestPoolStress从名字看，主要是想测一下“压力”，具体操作就是起了 10 个 goroutine 不断地向Pool里Put对象，然后又Get对象，看是否会出错。 TestPoolDequeue和TestPoolChain，都调用了testPoolDequeue，这是具体干活的。它需要传入一个PoolDequeue接口： // poolDequeue testing. type PoolDequeue interface { PushHead(val interface{}) bool PopHead() (interface{}, bool) PopTail() (interface{}, bool) } PoolDequeue是一个双端队列，可以从头部入队元素，从头部和尾部出队元素。调用函数时，前者传入NewPoolDequeue(16)，后者传入NewPoolChain()，底层其实都是poolDequeue这个结构体。 具体testPoolDequeue工作过程如下： 图3：testPoolDequeue工作流程\r总共起了 10 个 goroutine：1 个生产者，9 个消费者。生产者不断地从队列头pushHead元素到双端队列里去，并且每 push 10 次，就popHead一次；消费者则一直从队列尾取元素。不论是从队列头还是从队列尾取元素，都会在map里做标记，最后检验每个元素是不是只被取出过一次。 ","date":"2020-08-09","objectID":"/semaphore/:2:2","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"3. 原理结构 当Pool没有缓存的对象时，调用New方法生成一个新的对象。 type poolLocal struct { poolLocalInternal // 将 poolLocal 补齐至两个缓存行的倍数，防止 false sharing, // 每个缓存行具有 64 bytes，即 512 bit // 目前我们的处理器一般拥有 32 * 1024 / 64 = 512 条缓存行 // 伪共享，仅占位用，防止在 cache line 上分配多个 poolLocalInternal pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } // Local per-P Pool appendix. type poolLocalInternal struct { // P 的私有缓存区，使用时无需要加锁 private interface{} // 公共缓存区。本地 P 可以 pushHead/popHead；其他 P 则只能 popTail shared poolChain } 如果没有pad字段，那么当需要访问 0 号索引的poolLocal时，CPU 同时会把 0 号和 1 号索引同时加载到 cpu cache。在只修改 0 号索引的情况下，会让 1 号索引的poolLocal失效。这样，当其他线程想要读取 1 号索引时，发生 cache miss，还得重新再加载，对性能有损。增加一个pad，补齐缓存行，让相关的字段能独立地加载到缓存行就不会出现 false sharding 了。 关于poolChain结构体，是双端队列的实现： type poolChain struct { // 只有生产者会 push to，不用加锁 head *poolChainElt // 读写需要原子控制。 pop from tail *poolChainElt } type poolChainElt struct { poolDequeue // next 被 producer 写，consumer 读。所以只会从 nil 变成 non-nil // prev 被 consumer 写，producer 读。所以只会从 non-nil 变成 nil next, prev *poolChainElt } type poolDequeue struct { // The head index is stored in the most-significant bits so // that we can atomically add to it and the overflow is // harmless. // headTail 包含一个 32 位的 head 和一个 32 位的 tail 指针。这两个值都和 len(vals)-1 取模过。 // tail 是队列中最老的数据，head 指向下一个将要填充的 slot // slots 的有效范围是 [tail, head)，由 consumers 持有。 headTail uint64 // vals 是一个存储 interface{} 的环形队列，它的 size 必须是 2 的幂 // 如果 slot 为空，则 vals[i].typ 为空；否则，非空。 // 一个 slot 在这时宣告无效：tail 不指向它了，vals[i].typ 为 nil // 由 consumer 设置成 nil，由 producer 读 vals []eface } poolDequeue 被实现为单生产者、多消费者的固定大小的无锁（atomic实现） Ring式队列（底层存储使用数组，使用两个指针标记head、tail）。生产者可以从head插入、head删除，而消费者仅可从tail删除。 headTail指向队列的头和尾，通过位运算将head和tail存入headTail变量中。 对于双端队列的理解： 图4：双端队列\r我们看到Pool并没有直接使用poolDequeue，原因是它的大小是固定的，而Pool的大小是没有限制的。因此，在poolDequeue之上包装了一下，变成了一个poolChainElt的双向链表，可以动态增长。(摘录于segmentFault) ","date":"2020-08-09","objectID":"/semaphore/:2:3","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"3. semaphore ","date":"2020-08-09","objectID":"/semaphore/:3:0","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"1. 数据结构 sema.go中定义了一个全局变量，semtable数组。大小为251，元素为一个匿名结构体。这里为了避免伪共享问题做了一下内存填充。 // Prime to not correlate with any user patterns. const semTabSize = 251 var semtable [semTabSize]struct { root semaRoot pad [cpu.CacheLinePadSize - unsafe.Sizeof(semaRoot{})]byte } 每个元素持有的semaRoot为这个数据结构的核心。 // 为sync.Mutex准备的异步信号量 // golang.org/issue/17953 可以查看引入二级列表之前性能较差的程序示例test/locklinear.go type semaRoot struct { lock mutex treap *sudog // 平衡树的根节点 nwait uint32 // Number of waiters. Read w/o the lock. } semaRoot的结构看上去并不复杂，每个semaRoot持有一个具有不同地址(sudog.elem)的sudog平衡树，每个sudog都可以通过s.waitlink依次指向一个相同地址等待的sudog列表， 在具有相同等待地址的sudog内部列表上的操作时间复杂度都是$O(1)$。顶层semaRoot列表的扫描为$O(\\log n)$,其中$n$是阻止goroutines的不同信号量地址的数量。 问题\r既然节点都是sudog,那它是如何定义的？\rtype sudog struct { g *g next *sudog prev *sudog elem unsafe.Pointer //数据元素 (可能指向栈) // 下面的字段不会并发访问 // 对于channels, waitlink 只被g访问 // 对于semaphores, 所有自动(包括上面的)只有获取semaRoot的锁才能被访问 acquiretime int64 releasetime int64 ticket uint32 //isSelect表示g正在参与一个select，因此必须对g.selectDone进行CAS才能赢得唤醒竞争 isSelect bool //success表示channel c上的通信是否成功。如果goroutine因为在通道c上传递了一个值而被唤醒，则为true； //如果因为channel c关闭而被唤醒，则为false success bool parent *sudog // semaRoot binary tree waitlink *sudog // g.waiting list or semaRoot waittail *sudog // semaRoot c *hchan // channel } 这里可能就涉及到了Go的运行时调度的知识: 注意\rsudog是对goroutine的一种封装，比如当你使用channel时，goroutine在sending/receiving阻塞时是被封装成sudog放进阻塞队列进行等待。sudog是必需的，因为g和同步对象的关系是多对多的。一个g可以出现在许多等待列表上，因此一个g可能有很多个sudog。并且许多g可能正在等待同一个同步对象，因此一个对象可能有许多sudog sudog是从一个特殊的pool中分配。使用acquireSudog和releaseSudog来分配和释放他们。 其中的next、prev、parent字段构成了平衡树，waitlink和waittail构成了相同信号量地址的链表结构。 图5：sudog涉及的链表结构\r关于源码分析，我会在另一篇文章提到。 ","date":"2020-08-09","objectID":"/semaphore/:3:1","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"4 sync.Once ","date":"2020-08-09","objectID":"/semaphore/:4:0","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"1. sync.Once 用法 sync.Once是 Golang package 中使方法只执行一次的对象实现，作用与init函数类似。但也有所不同。 init函数是在文件包首次被加载的时候执行，且只执行一次 sync.Once 是在代码运行中需要的时候执行，且只执行一次 当一个函数不希望程序在一开始的时候就被执行的时候，我们可以使用sync.Once。 例如： 示例\rpackage main import ( \"fmt\" \"sync\" ) func main() { var once sync.Once onceBody := func() { fmt.Println(\"Only once\") } done := make(chan bool) for i := 0; i \u003c 10; i++ { go func() { once.Do(onceBody) done \u003c- true }() } for i := 0; i \u003c 10; i++ { \u003c-done } } # Output: Only once 在多数情况下，sync.Once被用于控制变量的初始化，这个变量的读写通常遵循单例模式，满足这三个条件： 当且仅当第一次读某个变量时，进行初始化（写操作） 变量被初始化过程中，所有读都被阻塞（读操作；当变量初始化完成后，读操作继续进行 变量仅初始化一次，初始化完成后驻留在内存里 需要注意的点： 注意\rOnce常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。 sync.Once只暴露了一个方法Do，你可以多次调用Do方法，但是只有第一次调用Do方法时f参数才会执行，这里的f是一个无参数无返回值的函数。 ","date":"2020-08-09","objectID":"/semaphore/:4:1","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Golang"],"content":"2. 原理结构 Once的结构体： type Once struct { done uint32 // 初始值为0表示还未执行过，1表示已经执行过 m Mutex } 其中，done成员变量: 1 表示资源未初始化，需要进一步初始化 0 表示资源已初始化，无需初始化，直接返回即可 m成员变量: 为了防止多个goroutine调用doSlow()初始化资源时，造成资源多次初始化，因此采用Mutex锁机制来保证有且仅初始化一次 Once所拥有的方法Do和doSlow: func (o *Once) Do(f func()) { // 判断done是否为0，若为0，表示未执行过，调用doSlow()方法初始化 if atomic.LoadUint32(\u0026o.done) == 0 { // Outlined slow-path to allow inlining of the fast-path. o.doSlow(f) } } // 加载资源 func (o *Once) doSlow(f func()) { o.m.Lock() defer o.m.Unlock() // 采用双重检测机制 加锁判断done是否为零 if o.done == 0 { // 执行完f()函数后，将done值设置为1 defer atomic.StoreUint32(\u0026o.done, 1) // 执行传入的f()函数 f() } 调用Do函数时，首先判断done值是否为0，若为1，表示传入的匿名函数f()已执行过，无需再次执行；若为0，表示传入的匿名函数f()还未执行过，则调用doSlow()函数进行初始化。 在doSlow()函数中，若并发的goroutine进入该函数中，为了保证仅有一个goroutine执行f()匿名函数。为此，需要加互斥锁保证只有一个goroutine进行初始化，同时采用了双检查的机制(double-checking)，再次判断o.done是否为0，如果为0，则是第一次执行，执行完毕后，就将o.done设置为 1，然后释放锁。 即使此时有多个 goroutine 同时进入了doSlow方法，因为双检查的机制，后续的 goroutine 会看到o.done的值为 1，也不会再次执行f。 这样既保证了并发的 goroutine 会等待f完成，而且还不会多次执行f。 ","date":"2020-08-09","objectID":"/semaphore/:4:2","tags":["Golang","mutex","sync","semaphore"],"title":"Golang 并发包 sync 系列","uri":"/semaphore/"},{"categories":["Kubernetes"],"content":"这篇文章总结了 Kubernetes 中 命令行的使用。","date":"2020-08-06","objectID":"/kubectl/","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"这篇文章总结了 Kubernetes 中 命令行的使用。 信息\r趁着今年黑色星期五的 Linux CNCF 社区报名有三五折优惠，我打算报考 CKAD 认证考试。在学习 Kubernetes 相关知识的同时，我也不忘总结一波有关 kubectl 的快捷命令。\r","date":"2020-08-06","objectID":"/kubectl/:0:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"1 Pod 生命周期管理 # 命令行创建 nginx pod kubectl run nginx --image=nginx --restart=Never --dry-run=client -n mynamespace -o yaml \u003e pod.yaml # 获取所有命名空间的 pod kubectl get po --all-namespaces # 运行 busybox 的同时打印 hello world kubectl run busybox --image=busybox -it --restart=Never -- echo 'hello world' # 进入容器 kubectl exec -it podName -n nsName /bin/sh # 列出 pod container 里面的 env variable kubectl exec podName -- printenv # 创建 pod 同时为 pod 添加标签 kubectl run nginx1 --image=nginx --restart=Never --labels=app=v1 # 列出所有添加标签的 pods kubectl get po --show-labels # 列出标有 app=v2 的 pods kubectl get po -l app=v2 # 更改 nginx2 的标签为 app=v2 kubectl label po nginx2 app=v2 --overwrite # 移除 nginx1 标有app的标签 kubectl label po nginx1 app- ","date":"2020-08-06","objectID":"/kubectl/:1:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"2 暴露 service 或 deployment # 输出为yaml文件（推荐） kubectl expose deployment nginx --port=80 --type=NodePort --target-port=80 --name=web1 -o yaml \u003e web1.yaml # 暴露端口 kubectl expose deployment nginx -n bigdata --port=80 --type=NodePort ","date":"2020-08-06","objectID":"/kubectl/:2:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"3 版本更新 # 更新 nginx 版本 kubectl set image deployment/nginx nginx=nginx:1.15 # 滚动更新 kubectl rolling-update frontend --image=image:v2 # 扩缩容 kubectl scale deployment nginx --replicas=10 ","date":"2020-08-06","objectID":"/kubectl/:3:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"4 回滚 # 查看更新过程 kubectl rollout status deployment/nginx --namespace=nsName # 如果更新成功, 返回值为0 kubectl rollout status deployment nginx-deployment --watch=false | grep -ic waiting # 查看变更历史版本信息 kubectl rollout history deployment/nginx kubectl rollout history deployment/nginx --revision=3 --namespace=nsName # 终止升级 kubectl rollout pause deployment/nginx --namespace=nsName # 继续升级 kubectl rollout resume deployment/review-demo --namespace=nsName # 回滚版本 kubectl rollout undo deployment/nginx --namespace=nsName kubectl rollout undo deployment/nginx --to-revision=3 --namespace=nsName ","date":"2020-08-06","objectID":"/kubectl/:4:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"5 探针 livenessProbe 和 readinessProbe kubectl run nginx --image=nginx --restart=Never --dry-run=client -o yaml \u003e pod.yaml # 然后编辑 pod.yaml 下的(containers -\u003e livenessProbe -\u003e exec -\u003e command -\u003e - 命令) 并保存 kubectl describe pod nginx | grep -i liveness # 检测是否 nginx 存活 ","date":"2020-08-06","objectID":"/kubectl/:5:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"6 Kubernetes configuration 配置 # 创建 secret kubectl create secret generic test-secret --from-literal='username=my-app' --from-literal='password=39528$vdg7Jb' # 创建 configMap echo -e \"DB_URL=localhost:3306\\nDB_USERNAME=postgres\" \u003e config.txt kubectl create cm db-config --from-env-file=config.txt # 创建 UID = 101 kubectl run nginx --image=nginx --restart=Never --dry-run=client -o yaml \u003e pod.yaml vi pod.yaml # spec -\u003e securityContext -\u003e runAsUser -\u003e 101 # requests 和 limits kubectl run nginx --image=nginx --restart=Never --requests='cpu=100m,memory=256Mi' --limits='cpu=200m,memory=512Mi' # 创建名字为 myuser 的 serviceAccount 并将它用在 nginx pod 上 kubectl create sa myuser kubectl run nginx --image=nginx --restart=Never --serviceaccount=myuser -o yaml --dry-run=client \u003e pod.yaml kubectl apply -f pod.yaml ","date":"2020-08-06","objectID":"/kubectl/:6:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"7 资源存储和分配 # pv 模板 apiVersion: v1 kind: PersistentVolume metadata: name: task-pv-volume labels: type: local spec: storageClassName: manual capacity: storage: 10Gi accessModes: - ReadWriteOnce hostPath: path: \"/mnt/data\" -- # pvc 模板 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: task-pv-claim spec: storageClassName: manual accessModes: - ReadWriteOnce resources: requests: storage: 3Gi # 区别在于: # pv: spec -\u003e capacity -\u003e storage 和 spec -\u003e hostPath -\u003e path # pvc: spec -\u003e resources -\u003e requests -\u003e storage ","date":"2020-08-06","objectID":"/kubectl/:7:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"8 表格汇总 类型 命令 描述 基础命令 create 通过文件名或标准输入创建资源 expose 将一个资源公开为一个新的Service run 在集群中运行一个特定的镜像 set 在对象上设置特定的功能 get 显示一个或多个资源 explain 文档参考资料 edit 使用默认的编辑器编辑资源 delete 通过文件名、标准输入、资源名称或标签选择器来删除资源 部署命令 rollout 管理资源的发布 rolling-update 对给定的复制控制器滚动更新 scale 扩容或缩容Pod、Deployment、ReplicaSet、RC或Job autoscale 创建一个自动选择扩容或缩容并设置Pod数量 集群管理命令 certificate 修改证书资源 cluster-info 显示集群信息 top 显示资源（CPU、Memory、Storage）使用。需要Heapster运行 cordon 标记节点不可调度 uncordon 标记节点可调度 drain 维护期间排除节点（驱除节点上的应用，准备下线维护） taint 设置污点属性 故障诊断和调试命令 describe 显示特定资源或资源组的详细信息 logs 在一个Pod中打印一个容器日志。如果Pod只有一个容器，容器名称是可选的 attach 附加到一个运行的容器 exec 执行命令到容器 port-forward 转发一个或多个本地端口到一个Pod proxy 运行一个proxy到Kubernetes API Server cp 拷贝文件或目录到容器 auth 检查授权 高级命令 apply 通过文件名或标准输入对资源应用配置 patch 使用补丁修改、更新资源的字段 replace 通过文件名或标准输入替换一个资源 convert 不同的API版本之间转换配置文件 设置命令 label 更新资源上的标签 annotate 更新资源上的注释 completion 用于实现kubectl工具自动补全 其他命令 api-versions 打印支持的API版本 config 修改kubeconfig文件（用于访问API，比如配置认证信息） help 所有命令帮助 plugin 运行一个命令行插件 version 打印客户端和服务版本信息 ","date":"2020-08-06","objectID":"/kubectl/:8:0","tags":["Kubernetes","kubectl"],"title":"Kubernetes kubectl 命令行总结","uri":"/kubectl/"},{"categories":["Kubernetes"],"content":"这篇文章总结了 Kubernetes 中 CRD 的知识体系和其中client-go的框架实现等等。","date":"2020-08-04","objectID":"/crd-introduction/","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"这篇文章总结了 Kubernetes 中 CRD 的知识体系和其中client-go的框架实现等等。 ","date":"2020-08-04","objectID":"/crd-introduction/:0:0","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"1 初识 CRD 和 Operator 框架 ","date":"2020-08-04","objectID":"/crd-introduction/:1:0","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"1.Custom Resource Define Custom Resource Define 简称 CRD，是 Kubernetes（v1.7+）为提高可扩展性，让开发者去自定义资源的一种方式。CRD 资源可以动态注册到集群中，注册完毕后，用户可以通过 kubectl 来创建访问这个自定义的资源对象，类似于操作 Pod 一样。不过需要注意的是 CRD 仅仅是资源的定义而已，需要一个对应的控制器去监听 CRD 的各种事件来添加自定义的业务逻辑。 ","date":"2020-08-04","objectID":"/crd-introduction/:1:1","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"2.YAML 文件格式 我们可以定义一个如下所示的 CRD 资源清单文件： # crd-demo.yaml apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: # name 必须匹配下面的spec字段：\u003cplural\u003e.\u003cgroup\u003e name: crontabs.stable.example.com spec: # group 名用于 REST API 中的定义：/apis/\u003cgroup\u003e/\u003cversion\u003e group: stable.example.com # 列出自定义资源的所有 API 版本 versions: - name: v1beta1 # 版本名称，比如 v1、v2beta1 等等 served: true # 是否开启通过 REST APIs 访问 `/apis/\u003cgroup\u003e/\u003cversion\u003e/...` storage: true # 必须将一个且只有一个版本标记为存储版本 schema: # 定义自定义对象的声明规范 openAPIV3Schema: description: Define CronTab YAML Spec type: object properties: spec: type: object properties: cronSpec: type: string image: type: string replicas: type: integer # 定义作用范围：Namespaced（命名空间级别）或者 Cluster（整个集群） scope: Namespaced names: # kind 是 singular 的一个驼峰形式定义，在资源清单中会使用 kind: CronTab # plural 名字用于 REST API 中的定义：/apis/\u003cgroup\u003e/\u003cversion\u003e/\u003cplural\u003e plural: crontabs # singular 名称用于 CLI 操作或显示的一个别名 singular: crontab # shortNames 相当于缩写形式 shortNames: - ct 我们在创建资源的时候，肯定不是任由我们随意去编写 YAML 文件的，当我们把上面的 CRD 文件提交给 Kubernetes 之后，Kubernetes 会对我们提交的声明文件进行校验，从定义可以看出 CRD 是基于 OpenAPI v3 schem 进行规范的。 使用 kubectl 来创建这个 CRD 资源清单： [root@master ~]# kubectl apply -f crd-demo.yaml customresourcedefinition.apiextensions.k8s.io/crontabs.stable.example.com created 然后我们就可以使用这个 API 端点来创建和管理自定义的对象，这些对象的类型就是上面创建的 CRD 对象规范中的 CronTab。 现在在 Kubernetes 集群中我们就多了一种新的资源叫 crontabs.stable.example.com，我们就可以使用它来定义一个 CronTab 资源对象了，这个自定义资源对象里面可以包含的字段我们在定义的时候通过 schema 进行了规范，比如现在我们来创建一个如下所示的资源清单： # crd-crontab-demo.yaml apiVersion: \"stable.example.com/v1beta1\" kind: CronTab metadata: name: my-new-cron-object spec: cronSpec: \"* * * * */5\" image: my-awesome-cron-image 直接创建这个对象： [root@master ~]# kubectl apply -f crd-crontab-demo.yaml crontab.stable.example.com/my-new-cron-object created 我们就可以用 kubectl 来管理我们这里创建 CronTab 对象了，比如： 示例\r[root@master ~]# kubectl get ct # 简写 NAME AGE my-new-cron-object 42s [root@master ~]# kubectl get crontab NAME AGE my-new-cron-object 88s ","date":"2020-08-04","objectID":"/crd-introduction/:1:2","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"3.kubebuilder 脚手架使用 创建一个目录，然后在里面运行 kubebuilder init 命令，初始化一个新项目。 $ cd go/src/github.com/peterliao96 $ mkdir builder-demo $ cd builder-demo # 开启 go modules $ export GO111MODULE=on $ export GOPROXY=https://goproxy.cn $ kubebuilder init --domain ydzs.io --owner peterliao96 --repo github.com/peterliao96/builder-demo # 创建一个新的 API（组/版本）为 “webapp/v1”，并在上面创建新的 Kind(CRD) “Guestbook” $ kubebuilder create api --group webapp --version v1 --kind Guestbook 上面的命令会创建文件 api/v1/guestbook_types.go，该文件中定义相关 API ，而针对于这一类型 (CRD) 的业务逻辑生成在 controller/guestbook_controller.go 文件中。 我们可以根据自己的需求去修改资源对象的定义结构，修改 api/v1/guestbook_types.go 文件： // api/v1/guestbook_types.go package v1 import ( metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" ) // EDIT THIS FILE! THIS IS SCAFFOLDING FOR YOU TO OWN! // NOTE: json tags are required. Any new fields you add must have json tags for the fields to be serialized. // GuestbookSpec defines the desired state of Guestbook type GuestbookSpec struct { // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run \"make\" to regenerate code after modifying this file // Foo is an example field of Guestbook. Edit guestbook_types.go to remove/update Foo string `json:\"foo,omitempty\"` } // GuestbookStatus defines the observed state of Guestbook type GuestbookStatus struct { // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster // Important: Run \"make\" to regenerate code after modifying this file } //+kubebuilder:object:root=true //+kubebuilder:subresource:status // Guestbook is the Schema for the guestbooks API type Guestbook struct { metav1.TypeMeta `json:\",inline\"` metav1.ObjectMeta `json:\"metadata,omitempty\"` Spec GuestbookSpec `json:\"spec,omitempty\"` Status GuestbookStatus `json:\"status,omitempty\"` } //+kubebuilder:object:root=true // GuestbookList contains a list of Guestbook type GuestbookList struct { metav1.TypeMeta `json:\",inline\"` metav1.ListMeta `json:\"metadata,omitempty\"` Items []Guestbook `json:\"items\"` } func init() { SchemeBuilder.Register(\u0026Guestbook{}, \u0026GuestbookList{}) } 本部分摘录于 Kubernetes 开发课文档中的 CRD介绍 和 kubebuilder 介绍。 ","date":"2020-08-04","objectID":"/crd-introduction/:1:3","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"2 client-go 实现原理 我们自定义的资源 CRD 创建完成以后，其实如果没有一个 controller 运行它的话，它并没有起到任何用处。于是，我们需要通过创建 controller 来运行 CRD。 要想了解 controller 的实现原理和方式，我们就需要了解下 client-go 这个库的实现，Kubernetes 部分代码也是基于这个库实现的，也包含了开发自定义控制器时可以使用的各种机制。 下图显示了 client-go 中的各个组件是如何公众的以及与我们要编写的自定义控制器代码的交互入口： 图1:client-go 实现流程图\r","date":"2020-08-04","objectID":"/crd-introduction/:2:0","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"1. 组件介绍 client-go 组件： Reflector：通过 Kubernetes API 监控 Kubernetes 的资源类型 采用 List/Watch 机制, 可以 Watch 任何资源包括 CRD 添加 object 对象到 FIFO 队列，然后 Informer 会从队列里面取数据 Informer：controller 机制的基础，循环处理 object 对象 从 Reflector 取出数据，然后将数据给到 Indexer 去缓存，提供对象事件的 handler 接口，只要给 Informer 添加 ResourceEventHandler 实例的回调函数，去实现 OnAdd(obj interface{})、 OnUpdate(oldObj, newObj interface{}) 和 OnDelete(obj interface{}) 这三个方法，就可以处理好资源的创建、更新和删除操作了。 Indexer：提供 object 对象的索引，是线程安全的，缓存对象信息 controller 组件： Informer reference: controller 需要创建合适的 Informer 才能通过 Informer reference 操作资源对象 Indexer reference: controller 创建 Indexer reference 然后去利用索引做相关处理 Resource Event Handlers：Informer 会回调这些 handlers Work queue: Resource Event Handlers 被回调后将 key 写到工作队列，这里的 key 相当于事件通知，后面根据取出事件后，做后续的处理 Process Item：从工作队列中取出 key 后进行后续处理，具体处理可以通过 Indexer reference controller 可以直接创建上述两个引用对象去处理，也可以采用工厂模式，官方都有相关示例 ","date":"2020-08-04","objectID":"/crd-introduction/:2:1","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Kubernetes"],"content":"2. 自定义 Controller 的控制流 图2：controller 工作流\r如上图所示主要有两个部分，一个是发生在 SharedIndexInformer 中，另外一个是在自定义控制器中。 Reflector 通过 Kubernetes APIServer 执行对象（比如 Pod）的 ListAndWatch 查询，记录和对象相关的三种事件类型 Added、Updated、Deleted，然后将它们传递到 DeltaFIFO 中去。 DeltaFIFO 接收到事件和 watch 事件对应的对象，然后将他们转换为 Delta 对象，这些 Delta 对象被附加到队列中去等待处理，对于已经删除的，会检查线程安全的 store 中是否已经存在该文件，从而可以避免在不存在某些内容时排队执行删除操作。 Cache 控制器（不要和自定义控制器混淆）调用 Pop() 方法从 DeltaFIFO 队列中出队列，Delta 对象将传递到 SharedIndexInformer 的 HandleDelta() 方法中以进行进一步处理。 根据 Delta 对象的操作（事件）类型，首先在 HandleDeltas 方法中通过 indexer 的方法将对对象保存到线程安全的 Store 中，然后，通过 SharedIndexInformer 中的 sharedProcessor 的 distribution() 方法将这些对象发送到事件 handlers，这些事件处理器由自定义控制器通过 SharedInformer 的方法比如 AddEventHandlerWithResyncPeriod() 进行注册。 已注册的事件处理器通过添加或更新时间的 MetaNamespaceKeyFunc() 或删除事件的 DeletionHandingMetaNamespaceKeyFunc() 将对象转换为格式为 namespace/name 或只是 name 的 key，然后将这个 key 添加到自定义控制器的 workqueue 中，workqueues 的实现可以在 util/workqueue 中找到。 自定义的控制器通过调用定义的 handlers 处理器从 workqueue 中 pop 一个 key 出来进行处理，handlers 将调用 indexer 的 GetByKey() 从线程安全的 store 中获取对象，我们的业务逻辑就是在这个 handlers 里面实现。 本部分摘录于 Kubernetes 文档中的 CRD controller 原理实现。 ","date":"2020-08-04","objectID":"/crd-introduction/:2:2","tags":["Golang","Kubernetes","CRD"],"title":"Kubernetes CRD Operator 开发系列 part 1: client-go框架介绍","uri":"/crd-introduction/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系：hashmap，包括其中的底层实现等等。","date":"2020-07-10","objectID":"/hashmap/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 9: hashmap","uri":"/hashmap/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系: hashmap，包括其中的底层实现等等。 ","date":"2020-07-10","objectID":"/hashmap/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 9: hashmap","uri":"/hashmap/"},{"categories":["Golang"],"content":"hashmap 问题\rHashmap 的内部结构是如何实现的呢？\r","date":"2020-07-10","objectID":"/hashmap/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 9: hashmap","uri":"/hashmap/"},{"categories":["Golang"],"content":"1. 内部结构 Go的 map 是 unordered map，即无法对 key 值排序遍历。跟传统的 hashmap 的实现方法一样，它通过一个 buckets 数组实现，所有元素被 hash 到数组的 bucket 中，buckets 就是指向了这个内存连续分配的数组。B字段说明 hash 表大小是2的指数，即$2^B$。每次扩容会增加到上次大小的两倍，即 $2^{B+1}$。当 bucket 填满后，将通过 overflow 指针来 mallocgc 一个bucket出来形成链表，也就是为哈希表解决冲突问题。 // A header for a Go map. type hmap struct { count int // len()返回的map的大小 即有多少kv对 flags uint8 B uint8 // 表示hash table总共有2^B个buckets hash0 uint32 // hash seed buckets unsafe.Pointer // 按照low hash值可查找的连续分配的数组，初始时为16个Buckets. oldbuckets unsafe.Pointer nevacuate uintptr overflow *[2]*[]*bmap //溢出链 当初始buckets都满了之后会使用overflow } // A bucket for a Go map. type bmap struct { tophash [bucketCnt]uint8 // Followed by bucketCnt keys and then bucketCnt values. // NOTE: packing all the keys together and then all the values together makes the // code a bit more complicated than alternating key/value/key/value/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer. } bucket map 的数据结构中，tophash 是个大小为 8(bucketCnt) 的数组，存储了8个 key 的 hash 值的高八位值。 技巧\r在对 key/value 对增删查的时候，先比较 key 的 hash 值高八位是否相等，然后再比较具体的key值。\r","date":"2020-07-10","objectID":"/hashmap/:1:1","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 9: hashmap","uri":"/hashmap/"},{"categories":["Golang"],"content":"2. map 初始化 B的初始大小是0，若指定了map的大小hint且hint大于8，那么buckets会在make时就通过newarray分配好，否则buckets会在第一次put的时候分配。随着hashmap中key/value对的增多，buckets需要重新分配，每一次都要重新hash并进行元素拷贝，所以最好在初始化时就给map指定一个合适的大小。 makemap 有h和bucket这两个参数，是留给编译器的。如果编译器决定hmap结构体和第一个bucket可以在栈上创建，这两个入参可能不是nil的。 // makemap implemments a Go map creation make(map[k]v, hint) func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap{ B := uint8(0) for ; hint \u003e bucketCnt \u0026\u0026 float32(hint) \u003e loadFactor*float32(uintptr(1)\u003c\u003cB); B++ { } // 确定初始B的初始值 这里hint是指kv对的数目 而每个buckets中可以保存8个kv对 // 因此上式是要找到满足不等式 hint \u003e loadFactor*(2^B) 最小的B if B != 0 { buckets = newarray(t.bucket, uintptr(1)\u003c\u003cB) } h = (*hmap)(newobject(t.hmap)) return h } ","date":"2020-07-10","objectID":"/hashmap/:1:2","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 9: hashmap","uri":"/hashmap/"},{"categories":["Golang"],"content":"3. map 存值 存储的步骤和第一部分的分析一致。首先用key的hash值低8位找到bucket，然后在bucket内部比对tophash和高8位与其对应的key值与入参key是否相等，若找到则更新这个值。若key不存在，则key优先存入在查找的过程中遇到的空的tophash数组位置。若当前的bucket已满则需要另外分配空间给这个key，新分配的bucket将挂在overflow链表后。 func mapassign1(t *maptype, h *hmap, key unsafe.Pointer, val unsafe.Pointer) { hash := alg.hash(key, uintptr(h.hash0)) if h.buckets == nil { h.buckets = newarray(t.bucket, 1) } again: //根据低8位hash值找到对应的buckets bucket := hash \u0026 (uintptr(1)\u003c\u003e (sys.PtrSize*8 - 8)) for { //遍历每一个bucket 对比所有tophash是否与top相等 //若找到空tophash位置则标记为可插入位置 for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == empty \u0026\u0026 inserti == nil { inserti = \u0026b.tophash[i] } continue } //当前tophash对应的key位置可以根据bucket的偏移量找到 k2 := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if !alg.equal(key, k2) { continue } //找到符合tophash对应的key位置 typedmemmove(t.elem, v2, val) goto done } //若overflow为空则break ovf := b.overflow(t) } // did not find mapping for key. Allocate new cell \u0026 add entry. if float32(h.count) \u003e= loadFactor*float32((uintptr(1)\u003c= bucketCnt { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } // all current buckets are full, allocate a new one. if inserti == nil { newb := (*bmap)(newobject(t.bucket)) h.setoverflow(t, b, newb) inserti = \u0026newb.tophash[0] } // store new key/value at insert position kmem := newobject(t.key) vmem := newobject(t.elem) typedmemmove(t.key, insertk, key) typedmemmove(t.elem, insertv, val) *inserti = top h.count++ } ","date":"2020-07-10","objectID":"/hashmap/:1:3","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 9: hashmap","uri":"/hashmap/"},{"categories":["Golang"],"content":"4. hash grow 扩容和迁移 在往map中存值时若所有的bucket已满，需要在堆中new新的空间时需要计算是否需要扩容。扩容的时机是count \u003e loadFactor(2^B)。这里的loadfactor选择为6.5。 问题\r为什么选取loadfactor为6.5呢？\r这是因为loadfactor和overflow溢出率、bytes/entry、hitprobe、missprobe相关。 overflow溢出率是指平均一个bucket有多少个kv的时候会溢出。 bytes/entry是指平均存一个kv需要额外存储多少字节的数据。 hitprobe是指找到一个存在的key平均需要找多少次。 missprobe是指找到一个不存在的key平均需要找多少次。选取6.5是为了平衡这组数据。 在没有溢出时hashmap总共可以存储8(2^B)个KV对，当hashmap已经存储到6.5(2^B)个KV对时表示hashmap已经趋于溢出，即很有可能在存值时用到overflow链表，这样会增加hitprobe和missprobe。 loadfactor %overflow bytes/entry hitprobe missprobe 4.00 2.13 20.77 3.00 4.00 4.50 4.05 17.30 3.25 4.50 5.00 6.85 14.77 3.50 5.00 5.50 10.55 12.94 3.75 5.50 6.00 15.27 11.67 4.00 6.00 6.50 20.90 10.79 4.25 6.50 7.00 27.14 10.15 4.50 7.00 7.50 34.03 9.73 4.50 7.50 8.00 41.10 9.40 5.00 8.00 但这个迁移并没有在扩容之后一次性完成，而是逐步完成的，每一次insert或remove时迁移1到2个pair，即增量扩容。 增量扩容的原因:主要是缩短map容器的响应时间。若hashmap很大扩容时很容易导致系统停顿无响应。 增量扩容本质上就是将总的扩容时间分摊到了每一次hash操作上。由于这个工作是逐渐完成的，导致数据一部分在old table中一部分在new table中。old的bucket不会删除，只是加上一个已删除的标记。只有当所有的bucket都从old table里迁移后才会将其释放掉。(摘录于Golang中文社区) ","date":"2020-07-10","objectID":"/hashmap/:1:4","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 9: hashmap","uri":"/hashmap/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系：mutex，包括其中的底层实现等等。","date":"2020-07-09","objectID":"/mutex/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 8: mutex 互斥锁","uri":"/mutex/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系: mutex，包括其中的底层实现等等。 ","date":"2020-07-09","objectID":"/mutex/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 8: mutex 互斥锁","uri":"/mutex/"},{"categories":["Golang"],"content":"mutex 互斥锁 ","date":"2020-07-09","objectID":"/mutex/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 8: mutex 互斥锁","uri":"/mutex/"},{"categories":["Golang"],"content":"1. mutex 底层结构 mutex 底层结构如下： type Mutex struct { state int32 sema uint32 } 零值就是一个有效的互斥锁，处于Unlocked状态。 state存储的是互斥锁的状态，加锁和解锁，都是通过atomic包提供的函数原子性，操作该字段。 sema用作一个信号量，主要用于等待队列。 Mutex有两种模式，在正常模式下，一个尝试加锁的goroutine会先自旋四次，自旋锁(如果不成功就一直尝试)，尝试通过原子操作获得锁，若几次自旋之后仍不能获得锁，则通过信号量排队等待。其中，所有等待者会按照先入先出FIFO的顺序排队。 图1：mutex正常模式\r但是当锁被释放，第一个等待者被唤醒后并不会直接拥有锁，而是需要和后来者竞争，也就是那些处于自旋阶段，尚未排队等待的goroutine。这种情况下后来者更有优势，一方面，它们正在CPU上运行，自然比刚被唤醒的goroutine更有优势，另一方面处于自旋状态的goroutine可以有很多，而被唤醒的goroutine每次只有一个，所以被唤醒的goroutine有很大概率拿不到锁。这种情况下它会被重新插入到队列的头部，而不是尾部。 图2：mutex饥饿模式\r而当一个goroutine本次加锁等待时间超过了1ms后，它会把当前Mutex从正常模式切换至“饥饿模式”。 在饥饿模式下，Mutex的所有权从执行Unlock的goroutine，直接传递给等待队列头部的goroutine，后来者不会自旋，也不会尝试获得锁，即使Mutex处于Unlocked的状态。它们会直接到队列的尾部排队等待。 图3：mutex饥饿模式下的goroutine队列\r当一个等待者获得锁之后，它会在以下两种情况时，将Mutex由饥饿模式切换回正常模式。 第一种情况是它的等待时间小于1ms，也就是它刚来不久 第二种情况是它是最后一个等待者，等待队列已经空了，后面自然就没有饥饿的goroutine了 注意\r综上所述，在正常模式下自旋和排队是同时存在的，执行lock的goroutine会先一边自旋，尝试4次后如果还没拿到锁，就需要去排队等待了，这种排队之前先让大家来抢的模式，能够有更高的吞吐量，因为频繁的挂起，唤醒goroutine会带来较多的开销。但是又不能无限制的自旋，要把自旋的开销控制在较小的范围内，所以在正常模式下，Mutex有更好的性能。 但是可能会出现队列尾端的goroutine迟迟抢不到锁(尾端延迟)的情况。\r图4：mutex饥饿模式下的goroutine不再自旋\r而饥饿模式不再尝试自旋，所有goroutine都要排队，严格的FIFO，对于防止出现尾端延迟来讲特别重要。 ","date":"2020-07-09","objectID":"/mutex/:1:1","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 8: mutex 互斥锁","uri":"/mutex/"},{"categories":["Golang"],"content":"这篇文章总结了 Golang 的知识体系: interface，包括其中的底层实现等等。","date":"2020-07-08","objectID":"/interface/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 7: interface","uri":"/interface/"},{"categories":["Golang"],"content":"这篇文章总结了 Golang 的知识体系: interface，包括其中的底层实现等等。 注意\r说起 Golang， 大家都会第一时间想到高并发和 Golang 作为主流的后端开发语言的优势，本文主要讲 Golang 主要知识体系，包括数组和切片、协程的调度原理、等待组 waitGroup、channel 的底层实现、互斥锁 mutex 的实现、interface 中的多态等等。\r","date":"2020-07-08","objectID":"/interface/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 7: interface","uri":"/interface/"},{"categories":["Golang"],"content":"interface ","date":"2020-07-08","objectID":"/interface/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 7: interface","uri":"/interface/"},{"categories":["Golang"],"content":"1. 多态 interface 定义了一个或一组 method(s)，若某个数据类型实现了 interface 中定义的那些被称为 “methods” 的函数，则称这些数据类型实现（implement）了 interface。举个例子来说明。 示例\r//定义了一个Mammal的接口，当中声明了一个Say函数。 type Mammal interface { Say() } 定义 Cat、Dog 和 Human 三个结构体，分别实现各自的 Say 方法： type Dog struct{} type Cat struct{} type Human struct{} func (d Dog) Say() { fmt.Println(\"woof\") } func (c Cat) Say() { fmt.Println(\"meow\") } func (h Human) Say() { fmt.Println(\"speak\") } 之后，我们尝试使用这个接口来接收各种结构体的对象，然后调用它们的 Say 方法： func main() { var m Mammal m = Dog{} m.Say() m = Cat{} m.Say() m = Human{} m.Say() } // print result: // woof // meow // speak ","date":"2020-07-08","objectID":"/interface/:1:1","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 7: interface","uri":"/interface/"},{"categories":["Golang"],"content":"2. 类型断言 (type assertion) //类型断言 //一个判断传入参数类型的函数 func just(items ...interface{}) { for index, v := range items { switch v.(type) { case bool: fmt.Printf(\"%d params is bool,value is %v\\n\", index, v) case int, int64, int32: fmt.Printf(\"%d params is int,value is %v\\n\", index, v) case float32, float64: fmt.Printf(\"%d params is float,value is %v\\n\", index, v) case string: fmt.Printf(\"%d params is string,value is %v\\n\", index, v) case Student: fmt.Printf(\"%d params student,value is %v\\n\", index, v) case *Student: fmt.Printf(\"%d params *student,value is %v\\n\", index, v) } } } 我们聊了面向对象中多态以及接口、类型断言的概念和写法，借此进一步了解了为什么 golang 中的接口设计非常出色，因为它解耦了接口和实现类之间的联系，使得进一步增加了我们编码的灵活度，解决了供需关系颠倒的问题。 ","date":"2020-07-08","objectID":"/interface/:1:2","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 7: interface","uri":"/interface/"},{"categories":["Golang"],"content":"这篇文章总结了 Golang 的知识体系 defer, panic 和 recover，包括其中的底层实现等等。","date":"2020-07-07","objectID":"/defer/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 6: defer, panic 和 recover","uri":"/defer/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系 defer, panic 和 recover，包括其中的底层实现等等。 ","date":"2020-07-07","objectID":"/defer/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 6: defer, panic 和 recover","uri":"/defer/"},{"categories":["Golang"],"content":"defer，panic 和 recover ","date":"2020-07-07","objectID":"/defer/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 6: defer, panic 和 recover","uri":"/defer/"},{"categories":["Golang"],"content":"1. defer 规则一：延迟函数的参数在 defer 语句出现时就已经确定下来了。例如： defer 语句中的 fmt.Println() 参数i值在 defer 出现时就已经确定下来，实际上是拷贝了一份。后面对变量i的修改不会影响 fmt.Println() 函数的执行，仍然打印\"0\"。 示例\rfunc a() { i := 0 defer fmt.Println(i) i++ return } 规则二：延迟函数执行按后进先出顺序执行，即先出现的 defer 最后执行。 定义 defer 类似于入栈操作，执行 defer 类似于出栈操作。设计 defer 的初衷是简化函数返回时资源清理的动作，资源往往有依赖顺序，比如先申请A资源，再跟据A资源申请B资源，跟据B资源申请C资源，即申请顺序是:A–\u003eB–\u003eC，释放时往往又要反向进行。这就是把 defer 设计成FIFO的原因。每申请到一个用完需要释放的资源时，立即定义一个 defer 来释放资源是个很好的习惯。例如： 函数拥有一个具名返回值 result，函数内部声明一个变量i，defer 指定一个延迟函数，最后返回变量i。延迟函数中递增 result。 函数输出2。函数的 return 语句并不是原子的，实际执行分为设置返回值–\u003eret，defer 语句实际执行在返回前，即拥有 defer 的函数返回过程是：设置返回值–\u003e执行 defer–\u003eret。所以 return 语句先把 result 设置为i的值，即1，defer 语句中又把 result 递增1，所以最终返回2。 示例\rfunc deferFuncReturn() (result int) { i := 1 defer func() { result++ }() return i } 规则三：延迟函数可能操作主函数的具名返回值。 定义 defer 的函数，即主函数可能有返回值，返回值有没有名字没有关系，defer 所作用的函数，即延迟函数可能会影响到返回值。例如我们再看一下上面 deferFuncReturn() 的例子: 示例\rfunc deferFuncReturn() (result int) { i := 1 defer func() { result++ }() return i } 该函数的 return 语句可以拆分成下面两行： result = i return 而延迟函数的执行正是在 return 之前，即加入 defer 后的执行过程如下： result = i result++ return 所以返回值为 result=1。 ","date":"2020-07-07","objectID":"/defer/:1:1","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 6: defer, panic 和 recover","uri":"/defer/"},{"categories":["Golang"],"content":"2. panic 主动：程序猿主动调用 panic() 函数； 被动：编译器的隐藏代码触发，或者内核发送给进程信号触发； panic 的具体实现，是依靠 defer 指针处理的，我们先来看一看 panic 的结构体： //runtime/runtime2.go type _panic struct { argp unsafe.Pointer // pointer to arguments of deferred call run during panic; cannot move - known to liblink arg interface{} // argument to panic link *_panic // link to earlier panic recovered bool // whether this panic is over aborted bool // the panic was aborted } _panic 是个结构体，存储了 defer 指针、参数，panic 列表的表头指针，和已恢复或已终止的信息。以下是 panic 的处理流程： 每个 goroutine 都有一个 panic 链表，运行时，遇到 panic 代码，会生成对应的 _panic 数据，存到这个链表的表头。 每执行完毕一个函数，如果没有 panic 发生，就跳过对应的 _panic 数据，回到正常流程，否则进入3。 如果有 panic 发生，处理链表中对应的 _panic，进入4。 如果 defer 链表（跟 panic 链表一样，也是每个 goroutine 一个）里存在 defer，按约定顺序执行延迟代码，进入5，否则进入8。 当 defer 链表执行到需要 recover 的时候，就交给 reflectcall 去调用 gorecover，进入6，否则进入7。 执行 recover，这时对应的 _panic 结构里的 recovered 字段标记为真，由 recovery 方法，负责安抚当前的 _panic，回到正常流程。 如果没 recover，那就进入死给你看流程，进入8。 最后，执行 fatalpanic 方法。 注意：因为 golang 的 goroutine 机制，panic 在不同的 goroutine 里面，是单独的，并不是整体处理。可能一个地方凉了，就会整体完蛋，这个要非常小心。 ","date":"2020-07-07","objectID":"/defer/:1:2","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 6: defer, panic 和 recover","uri":"/defer/"},{"categories":["Golang"],"content":"3. recover Golang 虽然没有 try catch 机制，但它有类似 recover 的机制， 示例\rpackage main import \"fmt\" func main() { fmt.Printf(\"%d\\n\", cal(1, 2)) fmt.Printf(\"%d\\n\", cal(5, 2)) fmt.Printf(\"%d\\n\", cal(5, 0)) fmt.Printf(\"%d\\n\", cal(9, 2)) } func cal(a, b int) int { defer func() { if err := recover(); err != nil { fmt.Printf(\"%s\\n\", err) } }() return a / b } 在 cal 函数里面每次终止的时候都会检查有没有异常产生，如果产生了我们可以处理，比如说记录日志，这样程序还可以继续执行下去。 ","date":"2020-07-07","objectID":"/defer/:1:3","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 6: defer, panic 和 recover","uri":"/defer/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系:context包，包括其中的底层实现等等。","date":"2020-07-06","objectID":"/context/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 5: context包","uri":"/context/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系:context包，包括其中的底层实现等等。 ","date":"2020-07-06","objectID":"/context/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 5: context包","uri":"/context/"},{"categories":["Golang"],"content":"context 包 context 包主要用于父子任务之间的同步取消信号，本质上是一种协程调度的方式。可以通过简化对于处理单个请求的多个 Goroutine 之间与请求域的数据、超时和退出等操作。来看两个例子： package main import( \"context\" \"sync\" \"fmt\" \"time\" ) // 我们定义一个worker function func worker(ctx context.Context, wg *sync.WaitGroup) error { defer wg.Done() for { select { case \u003c- ctx.Done(): return ctx.Err() default: fmt.Println(\"hello\") } } } func main(){ ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) var wg sync.WaitGroup for i := 0; i \u003c 10; i++{ wg.Add(1) go worker(ctx, \u0026wg) } time.Sleep(time.Second) cancel() wg.Wait() } 当并发体超时或者 main 主动停止 worker goroutine 时，worker goroutine 都可以安全退出。 另外在使用 context 时有两点值得注意：上游任务仅仅使用 context 通知下游任务不再需要，但不会直接干涉和中断下游任务的执行，由下游任务自行决定后续的处理操作，也就是说 context 的取消操作是无侵入的；context 是线程安全的，因为 context 本身是不可变的（immutable），因此可以放心地在多个协程中传递使用。 ","date":"2020-07-06","objectID":"/context/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 5: context包","uri":"/context/"},{"categories":["Golang"],"content":"这篇文章总结了 Golang 的知识体系: waitGroup，包括其中的底层实现等等。","date":"2020-07-05","objectID":"/waitgroup/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 4: 等待组 waitGroup","uri":"/waitgroup/"},{"categories":["Golang"],"content":"这篇文章总结了 Golang 的知识体系: waitGroup，包括其中的底层实现等等。 ","date":"2020-07-05","objectID":"/waitgroup/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 4: 等待组 waitGroup","uri":"/waitgroup/"},{"categories":["Golang"],"content":"等待组 WaitGroup 很多情况下，我们正需要知道 goroutine 是否完成。这需要借助 sync 包的 WaitGroup 来实现。WaitGroup 是 sync 包中的一个 struct 类型，用来收集需要等待执行完成的 goroutine。下面是它的定义： type WaitGroup struct { // Has unexported fields. } // A WaitGroup waits for a collection of goroutines to finish. The main // goroutine calls Add to set the number of goroutines to wait for. Then each // of the goroutines runs and calls Done when finished. At the same time, Wait // can be used to block until all goroutines have finished. // A WaitGroup must not be copied after first use. func (wg *WaitGroup) Add(delta int) func (wg *WaitGroup) Done() func (wg *WaitGroup) Wait() 它有3个方法： Add()：每次激活想要被等待完成的 goroutine 之前，先调用 Add()，用来设置或添加要等待完成的 goroutine 数量例如 Add(2) 或者两次调用 Add(1) 都会设置等待计数器的值为2，表示要等待2个 goroutine 完成 Done()：每次需要等待的 goroutine 在真正完成之前，应该调用该方法来人为表示 goroutine 完成了，该方法会对等待计数器减1 Wait()：在等待计数器减为0之前，Wait() 会一直阻塞当前的 goroutine package main import ( \"fmt\" \"sync\" \"time\" ) func process(i int, wg *sync.WaitGroup) { fmt.Println(\"started Goroutine \", i) time.Sleep(2 * time.Second) fmt.Printf(\"Goroutine %d ended\\n\", i) wg.Done() } func main() { no := 3 var wg sync.WaitGroup for i := 0; i \u003c no; i++ { wg.Add(1) go process(i, \u0026wg) } wg.Wait() fmt.Println(\"All go routines finished executing\") } 上面激活了3个 goroutine，每次激活 goroutine 之前，都先调用 Add() 方法增加一个需要等待的 goroutine 计数。每个 goroutine 都运行 process() 函数，这个函数在执行完成时需要调用 Done() 方法来表示 goroutine 的结束。激活3个 goroutine 后，main goroutine 会执行到 Wait()，由于每个激活的 goroutine 运行的 process() 都需要睡眠2秒，所以 main goroutine 在 Wait() 这里会阻塞一段时间(大约2秒)，当所有 goroutine 都完成后，等待计数器减为0，Wait() 将不再阻塞，于是 main goroutine 得以执行后面的 Println()。 注意\r还有一点需要特别注意的是 process() 中使用指针类型的 *sync.WaitGroup 作为参数，这里不能使用值类型的 sync.WaitGroup 作为参数，因为这意味着每个 goroutine 都拷贝一份 wg，每个 goroutine 都使用自己的 wg。这显然是不合理的，这3个 goroutine 应该共享一个 wg，才能知道这3个 goroutine 都完成了。实际上，如果使用值类型的参数，main goroutine 将会永久阻塞而导致产生死锁。\r","date":"2020-07-05","objectID":"/waitgroup/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 4: 等待组 waitGroup","uri":"/waitgroup/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系: channel，包括其中的底层实现等等。","date":"2020-07-04","objectID":"/channel/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 3: channel","uri":"/channel/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系: channel，包括其中的底层实现等等。 ","date":"2020-07-04","objectID":"/channel/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 3: channel","uri":"/channel/"},{"categories":["Golang"],"content":"channel channel 主要采用 CSP 并发模型实现的原理：不要通过共享内存来通信，而要通过通信来实现内存共享。它分为两种：带缓冲、不带缓冲。对不带缓冲的 channel 进行的操作实际上可以看作 “同步模式”，带缓冲的则称为 “异步模式”。 ","date":"2020-07-04","objectID":"/channel/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 3: channel","uri":"/channel/"},{"categories":["Golang"],"content":"1. 非缓冲的 channel 无缓冲的通道只有当发送方和接收方都准备好时才会传送数据, 否则准备好的一方将会被阻塞。 ","date":"2020-07-04","objectID":"/channel/:1:1","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 3: channel","uri":"/channel/"},{"categories":["Golang"],"content":"2. 带缓冲的 channel 有缓冲的 channel 区别在于只有当缓冲区被填满时, 才会阻塞发送者, 只有当缓冲区为空时才会阻塞接受者。值得注意的是， 关闭 channel 以后仍然可以读取数据 for range 循环可以持续从一个 channel 中接收数据 ","date":"2020-07-04","objectID":"/channel/:1:2","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 3: channel","uri":"/channel/"},{"categories":["Golang"],"content":"3. channel 的底层实现 1 channel 底层结构体 图1：channel 底层结构体\rbuf 是有缓冲的 channel 所特有的结构，用来存储缓存数据。是个循环链表 sendx 和 recvx 用于记录 buf 这个循环链表中的~发送或者接收的 ~index lock 是个互斥锁。 recvq 和 sendq 分别是接收 (\u003c-channel) 或者发送 (channel \u003c- xxx) 的 goroutine 抽象出来的结构体 (sudog) 的队列。是个双向链表 channel 的实现借助于结构体 hchan, 如下： type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } 2 send/recv 的细化操作 缓存链表中以上每一步的操作，都是需要加锁操作的！ 每一步的操作的细节可以细化为： 第一，加锁 第二，把数据从 goroutine 中 copy 到“队列”中(或者从队列中 copy 到 goroutine 中）。 第三，释放锁 goroutine 内存 copy 到 channel: 图2：内存条 copy 进 channel\rchannel 中的内存 copy 到 goroutine: 图3：channel 内存 copy 到内存条\r3. goroutine 的阻塞操作 goroutine 的阻塞操作，实际上是调用 send (ch \u003c- xx) 或者 recv ( \u003c-ch) 的时候主动触发的， //goroutine1 中，记做G1 ch := make(chan int, 3) ch \u003c- 1 ch \u003c- 1 ch \u003c- 1 当 channel 缓存满了以后，再次进行 send 操作 (ch\u003c-1) 的时候，会主动调用Go的调度器,让G1等待，并从让出M，让其他G去使用， 图4：Goroutine 调度\r同时G1也会被抽象成含有G1指针和 send 元素的 sudog 结构体保存到 hchan 的 sendq 中等待被唤醒。直到另一个 goroutine G2从缓存队列中取出数据，channel 会将等待队列中的G1推出，将G1当时 send 的数据推到缓存中，然后调用 Go 的 scheduler，唤醒G1，并把G1放到可运行的 goroutine 队列中。 ","date":"2020-07-04","objectID":"/channel/:1:3","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 3: channel","uri":"/channel/"},{"categories":["Golang"],"content":"4. channel 可能出现的状态 操作 nil的channel 正常的channel 已关闭的channel \u003c- ch 阻塞 成功或阻塞 读到零值 ch \u003c- 阻塞 成功或阻塞 panic close(ch) panic 成功 panic ","date":"2020-07-04","objectID":"/channel/:1:4","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 3: channel","uri":"/channel/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系：协程，包括其中的底层实现等等。","date":"2020-07-03","objectID":"/goroutine/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 2: 协程","uri":"/goroutine/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系：协程，包括其中的底层实现等等。 ","date":"2020-07-03","objectID":"/goroutine/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 2: 协程","uri":"/goroutine/"},{"categories":["Golang"],"content":"协程(coroutine) 在讲 goroutine 之前让我们先了解一下协程 (coroutine)，和线程类似，共享堆，不共享栈，协程的切换一般由程序员在代码中显式控制。它避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂。 ","date":"2020-07-03","objectID":"/goroutine/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 2: 协程","uri":"/goroutine/"},{"categories":["Golang"],"content":"1. golang 的协程(goroutine) Goroutine 和其他语言的协程（coroutine）在使用方式上类似，但在区别上看，协程不是并发的，而Goroutine支持并发的。因此Goroutine可以理解为一种Go语言的协程。同时它可以运行在一个或多个线程上。来看个例子: 示例\rfunc Hello() { fmt.Println(\"hello everybody , I'm Junqi Liao\") } func main() { go Hello() fmt.Println(\"Golang梦工厂\") } 上面的程序，我们使用go又开启了一个 goroutine 执行 Hello 方法，但是我们运行这个程序，运行结果如下: Golang梦工厂 这里出现这个问题的原因是我们启动的 goroutine 在 main 执行完就退出了。解决办法可以用 channel 通信让 goroutine 告诉 main 我执行完了，您再打印 “Golang梦工厂”。 func Hello(ch chan int) { fmt.Println(\"hello everybody , I'm asong\") ch \u003c- 1 } func main() { ch := make(chan int) go Hello(ch) \u003c-ch fmt.Println(\"Golang梦工厂\") } ","date":"2020-07-03","objectID":"/goroutine/:1:1","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 2: 协程","uri":"/goroutine/"},{"categories":["Golang"],"content":"2. goroutine 的调度模型 M代表线程 P代表处理器，每一个运行的M（线程）都必须绑定一个P（处理器） G代表 goroutine，每次使用 go 关键字的时候，都会创建一个G对象 图3：GMP调度模型\r当前有两个P，各自绑定了一个M，每个P上挂了一个本地 goroutine 队列，也有一个全局 goroutine 队列。流程： 每次使用 go 关键字声明时，一个G对象被创建并加入到本地G队列或者全局G队列。 检查是否有空闲的P（处理器），若有那么创建一个M（若有正在 sleep 的M那么直接唤醒它）与其绑定，然后这个M循环执行 goroutine 任务。 G任务执行的顺序是，先从本地队列中找。但若某个M（线程）发现本地队列为空，那么会从全局队列中截取 goroutine 来执行（一次性转移（全局队列的G个数/P个数））。如果全局队列也空，那么会随机从别的P那里截取 “一半” 的 goroutine 过来（偷窃任务），若所有的P的队列都为空，那么该M（线程）就会陷入 sleep。 ","date":"2020-07-03","objectID":"/goroutine/:1:2","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 2: 协程","uri":"/goroutine/"},{"categories":["Golang"],"content":"3. goroutine 协程池 超大规模并发的场景下，不加限制的大规模的 goroutine 可能造成内存暴涨，给机器带来极大的压力，吞吐量下降和处理速度变慢还是其次，更危险的是可能使得程序 crash。所以，goroutine 池化是有其现实意义的。 问题\r首先，100w个任务，是不是真的需要100w个 goroutine 来处理？\r未必！用1w个 goroutine 也一样可以处理，让一个 goroutine 多处理几个任务就是了嘛，池化的核心优势就在于对 goroutine 的复用。此举首先极大减轻了 runtime 调度 goroutine 的压力，其次，便是降低了对内存的消耗。 技巧\rGoroutine Pool 的实现思路大致如下： 启动服务之时先初始化一个 Goroutine Pool 池，这个 Pool 维护了一个类似栈的 LIFO 队列 ，里面存放负责处理任务的 Worker，然后在 client 端提交 task 到 Pool 中之后，在 Pool 内部，接收 task 之后的核心操作是： 检查当前 Worker 队列中是否有空闲的 Worker，如果有，取出执行当前的 task； 没有空闲 Worker，判断当前在运行的 Worker 是否已超过该 Pool 的容量，是 — 阻塞等待直至有 Worker 被放回 Pool；否 — 新开一个 Worker（goroutine）处理； 每个 Worker 执行完任务之后，放回 Pool 的队列中等待。 按照这个设计思路，一个高性能的 goroutine Pool，较好地解决了上述的大规模调度和资源占用的问题，在执行速度和内存占用方面相较于原生 goroutine 并发占有明显的优势，尤其是内存占用，因为复用，所以规避了无脑启动大规模 goroutine 的弊端，可以节省大量的内存。 ","date":"2020-07-03","objectID":"/goroutine/:1:3","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 2: 协程","uri":"/goroutine/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系数组与切片，包括其中的底层实现等等。","date":"2020-07-02","objectID":"/slice/","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 1: 数组与切片","uri":"/slice/"},{"categories":["Golang"],"content":"这篇文章总结了 Go 的知识体系数组与切片，包括其中的底层实现等等。 注意\r说起 Golang， 大家都会第一时间想到高并发和 Golang 作为主流的后端开发语言的优势，本文主要讲 Golang 主要知识体系，包括数组和切片、协程的调度原理、等待组 waitGroup、channel 的底层实现、互斥锁 mutex 的实现、interface 中的多态等等。\r","date":"2020-07-02","objectID":"/slice/:0:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 1: 数组与切片","uri":"/slice/"},{"categories":["Golang"],"content":"1 数组和切片 ","date":"2020-07-02","objectID":"/slice/:1:0","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 1: 数组与切片","uri":"/slice/"},{"categories":["Golang"],"content":"1. 切片的本质 切片的本质就是对底层数组的封装，它包含了三个信息 底层数组的指针 切片的长度(len) 切片的容量(cap) 切片的容量指的是数组中的头指针指向的位置至数组最后一位的长度。举个例子，现在有一个数组 a := [8]int {0,1,2,3,4,5,6,7}，切片 s1 := a[:5]，相应示意图如下 图1: 切片 s1 和底层数组 a\r切片 s2 := a[3:6]，相应示意图如下： 图2：切片 s2 和底层数组 a\r","date":"2020-07-02","objectID":"/slice/:1:1","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 1: 数组与切片","uri":"/slice/"},{"categories":["Golang"],"content":"2. 切片的扩容 Go 中切片扩容的策略是这样的： 如果切片的容量小于 1024 个元素，于是扩容的时候就翻倍增加容量。上面那个例子也验证了这一情况，总容量从原来的4个翻倍到现在的8个。 一旦元素个数超过 1024 个元素，那么增长因子就变成 1.25 ，即每次增加原来容量的四分之一。 技巧\r注意：扩容扩大的容量都是针对原来的容量而言的，而不是针对原来数组的长度而言的。\r举例 示例\r// make()函数创建切片 fmt.Println() var slices = make([]int, 4, 8) //[0 0 0 0] fmt.Println(slices) // 长度：4, 容量8 fmt.Printf(\"长度：%d, 容量%d\", len(slices), cap(slices)) 需要注意的是，golang 中没办法通过下标来给切片扩容，如果需要扩容，需要用到 append slices2 := []int{1,2,3,4} slices2 = append(slices2, 5) fmt.Println(slices2) // 输出结果 [1 2 3 4 5] 同时切片还可以将两个切片进行合并 // 合并切片 slices3 := []int{6,7,8} slices2 = append(slices2, slices3...) fmt.Println(slices2) // 输出结果 [1 2 3 4 5 6 7 8] ","date":"2020-07-02","objectID":"/slice/:1:2","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 1: 数组与切片","uri":"/slice/"},{"categories":["Golang"],"content":"3. 切片的传递问题 切片本身传递给函数形参时是引用传递，但 append 后，切片长度变化时会被重新分配内存，而原来的切片还是指向原来地址，致使与初始状况传进来的地址不一样，要想对其值有改变操作，需使用指针类型操作。 我们来看一道 leetcode 78: package main import \"fmt\" func helper(nums []int, res *[][]int, tmp []int, level int) { if len(tmp) \u003c= len(nums) { //长度一样的tmp用的是同一个地址，故可能会存在覆盖值得情况， // 长度不一样时重新开辟空间，将已有得元素复制进去 //*res = append(*res, tmp) 如此处，最终长度为1的tmp会被最后3这个元素全部覆盖 //以下相当于每次重新申请内存，使其指向的地址不一样，解决了最后地址一样的元素值被覆盖的状态状态 var a []int a = append(a, tmp[:] ...) //res = append(res, a) 如果此处不是指针引用传递，在append后，res重新分配内存，与之前传进来的res地址不一样，最终res仍为空值 *res = append(*res, a) } //fmt.Println(*res, \"---\u003e\", tmp) for i := level; i \u003c len(nums); i ++ { tmp = append(tmp, nums[i]) helper(nums, res, tmp, i + 1) tmp = tmp[:len(tmp) - 1] //相当于删除tmp末位的最后一个元素 } } func subsets(nums []int) [][]int { if len(nums) == 0 { return nil } var res [][]int var tmp []int helper(nums, \u0026res, tmp, 0) return res } func main() { pre := []int{1, 2, 3} fmt.Println(subsets(pre)) } //错误结果：[[] [3] [1 3] [1 2 3] [1 3] [3] [2 3] [3]]， 可以看出，长度为1的切片都被3覆盖了，这由于它们的地址不一样 //正确输出：[[] [1] [1 2] [1 2 3] [1 3] [2] [2 3] [3]]， 这是因为每次都为a分配内存，其地址都与之前的不一样，故最终的值没有被覆盖 ","date":"2020-07-02","objectID":"/slice/:1:3","tags":["Golang","goroutine","channel"],"title":"Go 基础知识与框架体系 part 1: 数组与切片","uri":"/slice/"},{"categories":null,"content":"游戏规则 点击小圆点，围住小猫。 你点击一次，小猫走一次。 直到你把小猫围住（赢），或者小猫走到边界并逃跑（输）。 ","date":"2021-02-02","objectID":"/categories/catch-the-cat/:1:0","tags":null,"title":"逮住那只猫!","uri":"/categories/catch-the-cat/"},{"categories":null,"content":" 这是由皮特ᴾᵗ 利用简洁、优雅且高效的 Hugo 框架开发的技术博客。 博主会不定时的分享关于各种热门技术，主要偏向后端开发、云原生以及其他热门技术栈等等。 ","date":"2020-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 皮特ᴾᵗ的博客 🌃","uri":"/about/"},{"categories":null,"content":"关于我 我是本科毕业于加拿大滑铁卢大学。过去四年和八个月份的本科生涯, 我主修金融数学，纯数学和统计辅修。同时，我对数学和编程都很感兴趣。在我的闲暇时间，我学习当下最热门的编程语言之一, 过去十年谷歌开发的语言 Go。 图1：学习 Go 的原因\r我学习 Go 和做 Go 后端开发工程师有三个简单的原因。首先，Go 的特色之处在于 goroutine, 因为 goroutine 涉及到运行时的高并发和低开销的上下文转换。其次，Go 的生态是由谷歌开发和维护，这很大程度上节省了 Go 开发人员在真实生产环境下的开发时间。最后是因为，Go 可以应用在很多技术栈，譬如 docker, Kubernetes 在云原生服务上开发应用等等。 ","date":"2020-08-02","objectID":"/about/:0:1","tags":null,"title":"关于 皮特ᴾᵗ的博客 🌃","uri":"/about/"},{"categories":null,"content":"感谢 感谢 Dillon 为 hugo 社区提供了这么棒的博客主题。 关于 LoveIt 的更多信息请查看 LICENSE 文件。 Dillon\rLoveIt主题作者\rHyper2t\rextremely hot 的数学编程专家\rHyper2t\rextremely hot 的云原生虚拟化专家\r","date":"2020-08-02","objectID":"/about/:0:2","tags":null,"title":"关于 皮特ᴾᵗ的博客 🌃","uri":"/about/"}]